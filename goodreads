#!/usr/bin/python
# -*- coding: utf-8 -*-
#
# Goodreads Analyzer 1.0
#
# apt-get install python-requests python-matplotlib
#
# https://www.goodreads.com/shelf/show/cyberpunk?page=1 1 - 25 (1250
# https://www.goodreads.com/shelf/show/science-fiction?page=1 - 25 (1250)
# https://www.goodreads.com/list/show/19341.Best_Science_Fiction?page=1 - 29 (2827)
#

import sqlite3,requests,StringIO,lxml.html,time,sys,re

GOOD='https://www.goodreads.com'
SHELF = GOOD + '/shelf/show/cyberpunk'

FOX = '/home/user/.mozilla/firefox/2wfpvx7b.default/cookies.sqlite'

#--------------------------------------

print('Goodreads Analyzer 1.0\n')

# COOKIE

# https://goodreads.com -> Remember login -> Login -> Quit)

COOKIES={}

print('Borowing cookies ...')

try:
	conn = sqlite3.connect(FOX)
	cur = conn.cursor()
	cur.execute("SELECT name,value FROM moz_cookies WHERE host = 'www.goodreads.com'")
	rows = cur.fetchall()
	for name,value in rows: COOKIES[name] = value
except:
	print('Failed to get cookies.')
	sys.exit(1)

# HARVEST & PARSE

print('Harwesting data  ...\n\n(this may take a while)\n')

DATASET = {}

for i in range(1, 3):#26
	req = requests.get(SHELF + '?page=' + str(i), cookies=COOKIES)
	if req.status_code == 200:
		p = lxml.html.HTMLParser()
		t = lxml.html.parse(StringIO.StringIO(req.text), p)
		o = t.xpath("//div[@class='elementList']")

		for i in range(0,len(o)):

			book = o[i].xpath(".//a[@class='bookTitle']")

			if book:
				book_title = book[0].text.encode('utf-8')
				book_url = book[0].get('href').encode('utf-8')
				book_id = re.sub('.*/(\d+).*', '\\1', book_url)

			author = o[i].xpath(".//a[@class='authorName']//span")

			if author:
				book_author = author[0].text.encode('utf-8')

			data = o[i].xpath(".//span[@class='greyText smallText']")

			if data:
				book_avg = re.findall('avg rating.*', data[0].text)
				book_ratings = re.findall('.*ratings', data[0].text)
				book_published = re.findall('published.*', data[0].text)

			DATASET[book_id] = {
				'title':book_title,
				'url':book_url,
				'author':book_author,
				'avg': re.sub('avg rating (.*) .*', '\\1', book_avg[0]),
				'ratings':re.sub('(.*) ratings.*', '\\1', book_ratings[0]).strip(),
				'year':re.sub('published (.*)', '\\1', book_published[0]).strip()
			}
	time.sleep(2)

print('Done.')

f = open('cyber-dataset.csv', 'a')

for B in DATASET:
	f.write(
		str(B) + ';' +
		DATASET[B]['title'] + ';' +
		DATASET[B]['url'] + ';' +
		DATASET[B]['author'] + ';' +
		DATASET[B]['avg'] + ';' +
		DATASET[B]['ratings'] + ';' +
		DATASET[B]['year'].decode('utf-8') +
		'\n'
	)

f.close()

# PLOT

# FILTER

# EXIT


